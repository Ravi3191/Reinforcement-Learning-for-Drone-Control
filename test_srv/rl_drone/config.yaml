#rl state
heading_dim: 1
velocity_dim: 1
action_dims: 2
state_dims: 2
n_channels: 4
img_height: 128
img_width: 128

high_vel: 1
low_vel: -1

high_heading: 1
low_heading: -1

value_lr: 0.0001
q_lr: 0.0001
policy_lr: 0.0001

batch_size: 64
latent_dims: 64
replay_size: 5000

gamma: 0.95
soft_tau: 0.01

max_episodes: 200
max_episode_len: 500

alpha: 0.4

GPU: True 
mapping: False

simulation_max_x: 1000
simulation_min_x: 0
simulation_max_y: 1000
simulation_min_y: 0

completion_reward: 100
crash_reward: -100
dist_reward_weight: 0.05

load_pretrained: False
pretrained_dir: '30112020212323'

root_dir: '/home/hersh/Programming/rl_logging2/'
logging_path: '/logging/'

observation_path: '/buffer/obs/'
next_observation_path: '/buffer/next_obs/'
